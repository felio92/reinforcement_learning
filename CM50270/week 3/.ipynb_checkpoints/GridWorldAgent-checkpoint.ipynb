{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    \n",
    "    def __init__(self, nCols=5, nRows=5, random_move_prob=0.2):\n",
    "        \n",
    "        #Initialise values that define the grid and some other essential parameters\n",
    "        self.nCols = nCols\n",
    "        self.nRows = nRows\n",
    "        if self.nRows<2 or self.nCols<2:\n",
    "            raise ValueError(\"Number of columns and rows may not be smaller than 2\")\n",
    "        self.nCells = nCols*nRows\n",
    "        self.random_move_prob = random_move_prob\n",
    "        \n",
    "        #Randomly choose bomb and gold position in the bottom half of the grid\n",
    "        bomb_gold_array = np.arange(0.5*self.nCells, self.nCells, 1, dtype=int)\n",
    "        self.bomb = np.random.choice(bomb_gold_array)\n",
    "        self.gold = np.random.choice(np.delete(bomb_gold_array, np.where(bomb_gold_array == self.bomb)))\n",
    "        \n",
    "        #Set reward array\n",
    "        self.reward = np.zeros(self.nCells)\n",
    "        self.reward[self.gold] = 10\n",
    "        self.reward[self.bomb] = -10\n",
    "        \n",
    "        #Set initial position of the agent randomly in the upper quadrant\n",
    "        ri = np.random.randint(0, 0.5*self.nRows)\n",
    "        rj = np.random.randint(0, 0.5*self.nCols)\n",
    "        self.agent = ri*self.nCols + rj\n",
    "        \n",
    "        #Define possible actions\n",
    "        self.actions = [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "        self.nActions = len(self.actions)\n",
    "        \n",
    "    def get_avaiable_actions(self):\n",
    "        return self.actions\n",
    "    \n",
    "    def isFinalPosition(self):\n",
    "        if self.agent in [self.gold, self.bomb]:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def reset(self):\n",
    "        ri = np.random.randint(0, 0.5*self.nRows)\n",
    "        rj = np.random.randint(0, 0.5*self.nCols)\n",
    "        self.agent = ri*self.nCols + rj\n",
    "    \n",
    "    def makeStep(self, action_index):\n",
    "        if np.random.uniform(0, 1)<self.random_move_prob:\n",
    "            action_indices = np.delete(np.arange(0, self.nActions, 1, dtype=int), action_index)\n",
    "            action_index = np.random.choice(action_indices)\n",
    "        action=self.actions[action_index]\n",
    "        \n",
    "        #test if proposed step would lead the agent outside of the grid. If yes, stay at current position.\n",
    "        #If not, update agent position according to action selected.\n",
    "        new_pos = self.agent\n",
    "        \n",
    "        if action == \"NORTH\":\n",
    "            proposed_pos = self.agent - self.nCols\n",
    "            if proposed_pos>=0:\n",
    "                new_pos = proposed_pos\n",
    "        elif action == \"SOUTH\":\n",
    "            proposed_pos = self.agent + self.nCols\n",
    "            if proposed_pos<self.nCells:\n",
    "                new_pos = proposed_pos\n",
    "        elif action == \"WEST\":\n",
    "            proposed_pos = self.agent - 1\n",
    "            if self.agent%self.nCols != 0:\n",
    "                new_pos = proposed_pos\n",
    "        elif action == \"EAST\":\n",
    "            proposed_pos = self.agent + 1\n",
    "            if self.agent%self.nCols != self.nCols - 1:\n",
    "                new_pos = proposed_pos\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action selected! Actions need to be NORTH, SOUTH, WEST or EAST\")\n",
    "        \n",
    "        self.agent = new_pos\n",
    "        \n",
    "        #Calculate reward of the agent's new position\n",
    "        reward = self.reward[self.agent]\n",
    "        reward += -1\n",
    "        \n",
    "        return new_pos, reward     \n",
    "    \n",
    "    def internalStateASCII(self, agent_pos):\n",
    "        string=''\n",
    "        for i in range(self.nCols+2):\n",
    "            string+=\"-\"\n",
    "        string+=\"\\n\"\n",
    "        for i in range(self.nRows):\n",
    "            string+=\"|\"\n",
    "            for j in range(self.nCols):\n",
    "                index = i*self.nCols + j\n",
    "                if index == agent_pos:\n",
    "                    string+=\"|\"\n",
    "                elif index == self.gold:\n",
    "                    string+=\"G\"\n",
    "                elif index == self.bomb:\n",
    "                    string+=\"B\"\n",
    "                else:\n",
    "                    string+=\" \"\n",
    "            string+=\"|\\n\"\n",
    "        for i in range(self.nCols+2):\n",
    "            string+=\"-\"\n",
    "        return string\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    def chooseAction(self, nActions):\n",
    "        actionIndex = np.random.choice(np.arange(0, nActions, 1, dtype=int))\n",
    "        return actionIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(10,10)\n",
    "ra = RandomAgent()\n",
    "nActions = gw.nActions\n",
    "for i in range(1000):\n",
    "    actionIndex = ra.chooseAction(nActions)\n",
    "    new_pos, rew = gw.makeStep(actionIndex)\n",
    "    print(gw.internalStateASCII(new_pos))\n",
    "    time.sleep(1/10)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent(object):\n",
    "    def __init__(self, env, gamma=1, alpha=0.1, eps=0.05):\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.nActions = env.nActions\n",
    "        self.qTable = np.zeros(shape=(env.nCells,self.nActions))\n",
    "    def chooseAction(self):\n",
    "        if np.random.uniform() < self.eps:\n",
    "            action_index = np.random.choice(np.arange(0, self.nActions, 1, dtype=int))\n",
    "        else:\n",
    "            pos = env.agent\n",
    "            max_q_value = max(self.qTable[pos])\n",
    "            max_indices = np.where(self.qTable[pos] == max_q_value)\n",
    "            action_index = np.random.choice(max_indices[0])\n",
    "            \n",
    "        return action_index\n",
    "    \n",
    "    def learn(self, old_pos, reward, new_pos, action_index):\n",
    "        qMax_new = max(self.qTable[new_pos])\n",
    "        q_old = self.qTable[old_pos, action_index]\n",
    "        self.qTable[old_pos, action_index] += self.alpha*(reward + self.gamma*qMax_new - q_old)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, agent, nGames=1000, maxSteps=1000):\n",
    "        rewards = np.zeros(nGames)\n",
    "        for i in range(nGames):\n",
    "            for j in range(maxSteps):\n",
    "                old_pos = env.agent\n",
    "                action_index = agent.chooseAction()\n",
    "                new_pos, reward = env.makeStep(action_index)\n",
    "                agent.learn(old_pos, reward, new_pos, action_index)\n",
    "                rewards[i]+=reward\n",
    "                if env.isFinalPosition():\n",
    "                    env.reset()\n",
    "                    break       \n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld(10, 10)\n",
    "env2 = GridWorld(10, 10)\n",
    "env2.reward = env.reward\n",
    "env2.gold = env.gold\n",
    "env2.bomb = env.bomb\n",
    "qa = QAgent(env)\n",
    "rewards=play(env, qa)\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    actionIndexQ = qa.chooseAction()\n",
    "    actionIndexR = ra.chooseAction(env2.nActions)\n",
    "    new_posQ, _ = env.makeStep(actionIndexQ)\n",
    "    new_posR, _ = env2.makeStep(actionIndexR)\n",
    "    if env.isFinalPosition():\n",
    "        env.reset()\n",
    "    if env2.isFinalPosition():\n",
    "        env2.reset()\n",
    "    string=''\n",
    "    string+=env.internalStateASCII(new_posQ)+\"\\n\"\n",
    "    string+=env2.internalStateASCII(new_posR)\n",
    "    print(string)\n",
    "    time.sleep(1/5)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
